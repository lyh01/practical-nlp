{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wz0jLNgTnMwF"
   },
   "source": [
    "In this notebook we will demonstrate various CNN and RNN models for the task of intent detection on the ATIS dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T02:51:26.312446Z",
     "start_time": "2020-01-21T02:51:15.878759Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7GnbW58Yi_7P",
    "outputId": "67fd2a56-575c-4f98-9628-aae205443f8a"
   },
   "outputs": [],
   "source": [
    "\n",
    "#making the necessary imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import random\n",
    "random.seed(0)#for reproducability of results\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGFhMpnjo4L1"
   },
   "source": [
    "Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:16:45.725380Z",
     "start_time": "2020-01-21T03:16:45.669373Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pl5A0Kwji_7h",
    "outputId": "e7f3b18e-0d39-4428-957b-4e247f3c192b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training sentences : 4952\nNumber of unique intents : 17\n('i want to fly from boston at 838 am and arrive in denver at 1110 in the morning', 'atis_flight')\n('what flights are available from pittsburgh to baltimore on thursday morning', 'atis_flight')\n('what is the arrival time in san francisco for the 755 am flight leaving washington', 'atis_flight_time')\n('cheapest airfare from tacoma to orlando', 'atis_airfare')\n('round trip fares from pittsburgh to philadelphia under 1000 dollars', 'atis_airfare')\n"
     ]
    }
   ],
   "source": [
    "#utils is included in this repository'c Ch6 folder under folder name \"Data\"\n",
    "from Data.utils import fetch_data, read_method\n",
    "\n",
    "sents,labels,intents = fetch_data('Data/data2/atis.train.w-intent.iob')\n",
    "\n",
    "train_sentences = [\" \".join(i) for i in sents]\n",
    "\n",
    "train_texts = train_sentences\n",
    "train_labels= intents.tolist()\n",
    "\n",
    "vals = []\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    if \"#\" in train_labels[i]:\n",
    "        vals.append(i)\n",
    "        \n",
    "for i in vals[::-1]:\n",
    "    train_labels.pop(i)\n",
    "    train_texts.pop(i)\n",
    "\n",
    "print (\"Number of training sentences :\",len(train_texts))\n",
    "print (\"Number of unique intents :\",len(set(train_labels)))\n",
    "\n",
    "for i in zip(train_texts[:5], train_labels[:5]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qckNEPKRo8_V"
   },
   "source": [
    "Loading the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:16:53.184193Z",
     "start_time": "2020-01-21T03:16:52.523898Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zQynEfVmi_7m",
    "outputId": "38ecc729-f2de-4500-e594-ad4d073dacdf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "atis_day_name\natis_day_name\nNumber of testing sentences : 876\nNumber of unique intents : 15\n('i would like to find a flight from charlotte to las vegas that makes a stop in st. louis', 'atis_flight')\n('on april first i need a ticket from tacoma to san jose departing before 7 am', 'atis_airfare')\n('on april first i need a flight going from phoenix to san diego', 'atis_flight')\n('i would like a flight traveling one way from phoenix to san diego on april first', 'atis_flight')\n('i would like a flight from orlando to salt lake city for april first on delta airlines', 'atis_flight')\n"
     ]
    }
   ],
   "source": [
    "from Data.utils import fetch_data, read_method\n",
    "\n",
    "sents,labels,intents = fetch_data('Data/data2/atis.test.w-intent.iob')\n",
    "\n",
    "test_sentences = [\" \".join(i) for i in sents]\n",
    "\n",
    "test_texts = test_sentences\n",
    "test_labels = intents.tolist()\n",
    "\n",
    "new_labels = set(test_labels) - set(train_labels)\n",
    "\n",
    "vals = []\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if \"#\" in test_labels[i]:\n",
    "        vals.append(i)\n",
    "    elif test_labels[i] in new_labels:\n",
    "        print(test_labels[i])\n",
    "        vals.append(i)\n",
    "        \n",
    "for i in vals[::-1]:\n",
    "    test_labels.pop(i)\n",
    "    test_texts.pop(i)\n",
    "\n",
    "print (\"Number of testing sentences :\",len(test_texts))\n",
    "print (\"Number of unique intents :\",len(set(test_labels)))\n",
    "\n",
    "for i in zip(test_texts[:5], test_labels[:5]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUZsI3ZmpBA2"
   },
   "source": [
    "Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 300\n",
    "MAX_NUM_WORDS = 20000 \n",
    "EMBEDDING_DIM = 100 \n",
    "VALIDATION_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:16:58.708150Z",
     "start_time": "2020-01-21T03:16:58.445025Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sk1EXJANi_7p",
    "outputId": "a89ff82e-7cda-4fa3-84c2-eb38679ff881"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 897 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts) #Converting text to a vector of word indexes\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:17:08.464993Z",
     "start_time": "2020-01-21T03:17:08.455586Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "PyTlYCLQi_76"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:18:09.843555Z",
     "start_time": "2020-01-21T03:18:09.802336Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XPdDoAAli_8K",
    "outputId": "ee82e0a6-39a1-4893-b9ea-a45db8f30236"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Splitting the train data into train and valid is done\n"
     ]
    }
   ],
   "source": [
    "#Converting this to sequences to be fed into neural network. Max seq. len is 1000 as set earlier\n",
    " #initial padding of 0s, until vector is of size MAX_SEQUENCE_LENGTH\n",
    "trainvalid_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "trainvalid_labels = to_categorical(train_labels)\n",
    "\n",
    "test_labels = to_categorical(np.asarray(test_labels), num_classes= trainvalid_labels.shape[1])\n",
    "\n",
    "# split the training data into a training set and a validation set\n",
    "indices = np.arange(trainvalid_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "trainvalid_data = trainvalid_data[indices]\n",
    "trainvalid_labels = trainvalid_labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * trainvalid_data.shape[0])\n",
    "x_train = trainvalid_data[:-num_validation_samples]\n",
    "y_train = trainvalid_labels[:-num_validation_samples]\n",
    "x_val = trainvalid_data[-num_validation_samples:]\n",
    "y_val = trainvalid_labels[-num_validation_samples:]\n",
    "#This is the data we will use for CNN and RNN training\n",
    "print('Splitting the train data into train and valid is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:18:41.097840Z",
     "start_time": "2020-01-21T03:18:14.824841Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gSKw8NHxi_8O",
    "outputId": "fb7a5b97-883c-473f-e016-be984bf4f194"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Preparing embedding matrix.\n",
      "Found 400000 word vectors in Glove embeddings.\n",
      "Preparing of embedding matrix is done\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "# Download GloVe 6B from here: https://nlp.stanford.edu/projects/glove/\n",
    "BASE_DIR = 'Data'\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors in Glove embeddings.' % len(embeddings_index))\n",
    "#print(embeddings_index[\"google\"])\n",
    "\n",
    "# prepare embedding matrix - rows are the words from word_index, columns are the embeddings of that word from glove.\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load these pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "print(\"Preparing of embedding matrix is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:19:56.592225Z",
     "start_time": "2020-01-21T03:19:49.795954Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "w1sdtUNYi_8T",
    "outputId": "bc393907-c69f-4371-8214-ad85f716dbc8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Define a 1D CNN model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 296, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 59, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 55, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 7, 128)            82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 336,729\n",
      "Trainable params: 246,929\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "28/28 [==============================] - 31s 928ms/step - loss: 1.3981 - acc: 0.6484 - val_loss: 0.8634 - val_acc: 0.7380\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.9233 - acc: 0.7272\n",
      "Test accuracy with CNN: 0.7271689772605896\n"
     ]
    }
   ],
   "source": [
    "print('Define a 1D CNN model.')\n",
    "\n",
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(embedding_layer)\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(GlobalMaxPooling1D())\n",
    "cnnmodel.add(Dense(128, activation='relu'))\n",
    "cnnmodel.add(Dense(len(trainvalid_labels[0]), activation='softmax'))\n",
    "\n",
    "cnnmodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "cnnmodel.summary()\n",
    "\n",
    "#Train the model. Tune to validation set. \n",
    "cnnmodel.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1, validation_data=(x_val, y_val))\n",
    "#Evaluate on test set:\n",
    "score, acc = cnnmodel.evaluate(test_data, test_labels)\n",
    "print('Test accuracy with CNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm cnnmodel_Ch6_01_cnn.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "cnnmodel.save(\"cnnmodel_Ch6_01_cnn.h5\")\n",
    "#del cnnmodel_reload\n",
    "cnnmodel_reload=load_model(\"cnnmodel_Ch6_01_cnn.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "28/28 [==============================] - 3s 88ms/step - loss: 0.9233 - acc: 0.7272\n",
      "Test accuracy with CNN: 0.7271689772605896\n"
     ]
    }
   ],
   "source": [
    "score, acc = cnnmodel.evaluate(test_data, test_labels)\n",
    "print('Test accuracy with CNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "28/28 [==============================] - 4s 128ms/step - loss: 0.9233 - acc: 0.7272\n",
      "Test accuracy with CNN: 0.7271689772605896\n"
     ]
    }
   ],
   "source": [
    "score, acc = cnnmodel_reload.evaluate(test_data, test_labels)\n",
    "print('Test accuracy with CNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_reload = cnnmodel_reload.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_original = cnnmodel.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(876, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "predictions_reload.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(876, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "predictions_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2.74056569e-03, 1.19571155e-02, 6.03919216e-02, 5.21824993e-02,\n",
       "       9.10208677e-04, 1.31386355e-03, 9.41800477e-04, 6.30950148e-04,\n",
       "       1.88868155e-03, 8.30409169e-01, 2.34467792e-03, 1.05756670e-02,\n",
       "       2.17650924e-03, 1.60767511e-02, 1.83339987e-03, 3.25839524e-03,\n",
       "       3.67942237e-04], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "predictions_reload[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2.74056569e-03, 1.19571155e-02, 6.03919216e-02, 5.21824993e-02,\n",
       "       9.10208677e-04, 1.31386355e-03, 9.41800477e-04, 6.30950148e-04,\n",
       "       1.88868155e-03, 8.30409169e-01, 2.34467792e-03, 1.05756670e-02,\n",
       "       2.17650924e-03, 1.60767511e-02, 1.83339987e-03, 3.25839524e-03,\n",
       "       3.67942237e-04], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "predictions_original[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.01226109, 0.08262777, 0.0635693 , 0.02164723, 0.00386606,\n",
       "        0.00638703, 0.00073836, 0.00411973, 0.0021619 , 0.7346508 ,\n",
       "        0.00483226, 0.01642147, 0.00528206, 0.02222055, 0.00266573,\n",
       "        0.01262821, 0.00392044]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "cnnmodel.predict(test_data[0].reshape(1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 17), dtype=float32, numpy=\n",
       "array([[0.01226109, 0.08262777, 0.0635693 , 0.02164723, 0.00386606,\n",
       "        0.00638703, 0.00073836, 0.00411973, 0.0021619 , 0.7346508 ,\n",
       "        0.00483226, 0.01642147, 0.00528206, 0.02222055, 0.00266573,\n",
       "        0.01262821, 0.00392044]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "cnnmodel_reload(test_data[0].reshape(1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__self__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__text_signature__']"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "test1=()\n",
    "dir(test1.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "cannot convert dictionary update sequence element #0 to a sequence",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9fb859e606fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot convert dictionary update sequence element #0 to a sequence"
     ]
    }
   ],
   "source": [
    "for i in test_data:\n",
    "   test1.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "type(test1[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'append',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort']"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "dir(list(test1['rec1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  18,  39,  25,   1,  90,\n",
       "        13,   8,   2, 103,   1,  98,  95,  30, 343,  13, 109,  15,  87,\n",
       "       178])"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "np.array( tuple(test1['rec1']), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.01226109, 0.08262777, 0.0635693 , 0.02164723, 0.00386606,\n",
       "        0.00638703, 0.00073836, 0.00411973, 0.0021619 , 0.7346508 ,\n",
       "        0.00483226, 0.01642147, 0.00528206, 0.02222055, 0.00266573,\n",
       "        0.01262821, 0.00392044]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "cnnmodel_reload.predict(np.array(test1['rec1']).reshape(1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Define a 1D CNN model.\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 296, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 59, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 55, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 7, 128)            82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 336,729\n",
      "Trainable params: 246,929\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/24\n",
      "28/28 [==============================] - 11s 333ms/step - loss: 1.4813 - acc: 0.6975 - val_loss: 0.9705 - val_acc: 0.7993\n",
      "Epoch 2/24\n",
      "28/28 [==============================] - 7s 256ms/step - loss: 0.8270 - acc: 0.7687 - val_loss: 0.5581 - val_acc: 0.8283\n",
      "Epoch 3/24\n",
      "28/28 [==============================] - 7s 254ms/step - loss: 0.5399 - acc: 0.8579 - val_loss: 0.4938 - val_acc: 0.8687\n",
      "Epoch 4/24\n",
      "28/28 [==============================] - 9s 306ms/step - loss: 0.3888 - acc: 0.8966 - val_loss: 0.2997 - val_acc: 0.9199\n",
      "Epoch 5/24\n",
      "28/28 [==============================] - 8s 274ms/step - loss: 0.2912 - acc: 0.9233 - val_loss: 0.2299 - val_acc: 0.9394\n",
      "Epoch 6/24\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 0.1882 - acc: 0.9464 - val_loss: 0.1799 - val_acc: 0.9542\n",
      "Epoch 7/24\n",
      "28/28 [==============================] - 8s 295ms/step - loss: 0.1599 - acc: 0.9562 - val_loss: 0.1559 - val_acc: 0.9596\n",
      "Epoch 8/24\n",
      "28/28 [==============================] - 8s 281ms/step - loss: 0.1066 - acc: 0.9672 - val_loss: 0.2650 - val_acc: 0.9380\n",
      "Epoch 9/24\n",
      "28/28 [==============================] - 8s 291ms/step - loss: 0.1420 - acc: 0.9606 - val_loss: 0.1450 - val_acc: 0.9596\n",
      "Epoch 10/24\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 0.1203 - acc: 0.9677 - val_loss: 0.1247 - val_acc: 0.9663\n",
      "Epoch 11/24\n",
      "28/28 [==============================] - 8s 296ms/step - loss: 0.0851 - acc: 0.9782 - val_loss: 0.1175 - val_acc: 0.9704\n",
      "Epoch 12/24\n",
      "28/28 [==============================] - 8s 291ms/step - loss: 0.0786 - acc: 0.9792 - val_loss: 0.1066 - val_acc: 0.9710\n",
      "Epoch 13/24\n",
      "28/28 [==============================] - 8s 273ms/step - loss: 0.0269 - acc: 0.9938 - val_loss: 0.3169 - val_acc: 0.9340\n",
      "Epoch 14/24\n",
      "28/28 [==============================] - 9s 305ms/step - loss: 0.1028 - acc: 0.9773 - val_loss: 0.1031 - val_acc: 0.9744\n",
      "Epoch 15/24\n",
      "28/28 [==============================] - 8s 280ms/step - loss: 0.0196 - acc: 0.9972 - val_loss: 0.1048 - val_acc: 0.9744\n",
      "Epoch 16/24\n",
      "28/28 [==============================] - 8s 282ms/step - loss: 0.0270 - acc: 0.9940 - val_loss: 0.1098 - val_acc: 0.9744\n",
      "Epoch 17/24\n",
      "28/28 [==============================] - 9s 317ms/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.7108 - val_acc: 0.8525\n",
      "Epoch 18/24\n",
      "28/28 [==============================] - 9s 308ms/step - loss: 0.0915 - acc: 0.9777 - val_loss: 0.1598 - val_acc: 0.9710\n",
      "Epoch 19/24\n",
      "28/28 [==============================] - 9s 321ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.1596 - val_acc: 0.9724\n",
      "Epoch 20/24\n",
      "28/28 [==============================] - 8s 286ms/step - loss: 0.1132 - acc: 0.9779 - val_loss: 0.1082 - val_acc: 0.9717\n",
      "Epoch 21/24\n",
      "28/28 [==============================] - 8s 277ms/step - loss: 0.0054 - acc: 0.9989 - val_loss: 0.1120 - val_acc: 0.9737\n",
      "Epoch 22/24\n",
      "28/28 [==============================] - 8s 294ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.1176 - val_acc: 0.9758\n",
      "Epoch 23/24\n",
      "28/28 [==============================] - 8s 291ms/step - loss: 0.0274 - acc: 0.9945 - val_loss: 0.1026 - val_acc: 0.9764\n",
      "Epoch 24/24\n",
      "28/28 [==============================] - 8s 269ms/step - loss: 0.0045 - acc: 0.9993 - val_loss: 0.1282 - val_acc: 0.9737\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.2641 - acc: 0.9498\n",
      "Test accuracy with CNN: 0.9497717022895813\n"
     ]
    }
   ],
   "source": [
    "print('Define a 1D CNN model.')\n",
    "\n",
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(embedding_layer)\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(GlobalMaxPooling1D())\n",
    "cnnmodel.add(Dense(128, activation='relu'))\n",
    "cnnmodel.add(Dense(len(trainvalid_labels[0]), activation='softmax'))\n",
    "\n",
    "cnnmodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "cnnmodel.summary()\n",
    "\n",
    "#Train the model. Tune to validation set. \n",
    "cnnmodel.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=24, validation_data=(x_val, y_val))\n",
    "#Evaluate on test set:\n",
    "score, acc = cnnmodel.evaluate(test_data, test_labels)\n",
    "print('Test accuracy with CNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:20:48.874312Z",
     "start_time": "2020-01-21T03:20:39.637994Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ekMBb2Ski_8j",
    "outputId": "c6f2c28d-6e5f-4d69-85b7-b708d9c8475c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training a CNN model, training embedding layer on the fly instead of using pre-trained embeddings\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 2,824,849\n",
      "Trainable params: 2,824,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "28/28 [==============================] - 56s 2s/step - loss: 1.6637 - acc: 0.6363 - val_loss: 0.9301 - val_acc: 0.7387\n",
      "28/28 [==============================] - 4s 139ms/step - loss: 1.0014 - acc: 0.7215\n",
      "Test accuracy with CNN: 0.7214611768722534\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training a CNN model, training embedding layer on the fly instead of using pre-trained embeddings\")\n",
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(Embedding(MAX_NUM_WORDS, 128))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(MaxPooling1D(5))\n",
    "cnnmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "cnnmodel.add(GlobalMaxPooling1D())\n",
    "cnnmodel.add(Dense(128, activation='relu'))\n",
    "cnnmodel.add(Dense(len(trainvalid_labels[0]), activation='softmax'))\n",
    "\n",
    "cnnmodel.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "cnnmodel.summary()\n",
    "\n",
    "#Train the model. Tune to validation set. \n",
    "cnnmodel.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1, validation_data=(x_val, y_val))\n",
    "#Evaluate on test set:\n",
    "score, acc = cnnmodel.evaluate(test_data, test_labels)\n",
    "print('Test accuracy with CNN:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:23:06.806061Z",
     "start_time": "2020-01-21T03:21:34.339598Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lE5578-ei_8m",
    "outputId": "2d245c0d-fbdf-4986-c29e-133ce5ab732d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training an LSTM model, training embedding layer on the fly\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 2,693,777\n",
      "Trainable params: 2,693,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training the RNN\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 309s 3s/step - loss: 0.2851 - accuracy: 0.6999 - val_loss: 0.1013 - val_accuracy: 0.7387\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 300s 3s/step - loss: 0.0976 - accuracy: 0.7493 - val_loss: 0.0983 - val_accuracy: 0.7387\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 406s 4s/step - loss: 0.0955 - accuracy: 0.7354 - val_loss: 0.0851 - val_accuracy: 0.7549\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 348s 3s/step - loss: 0.0755 - accuracy: 0.7771 - val_loss: 0.0653 - val_accuracy: 0.8236\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 261s 2s/step - loss: 0.0561 - accuracy: 0.8514 - val_loss: 0.0518 - val_accuracy: 0.8653\n",
      "28/28 [==============================] - 8s 270ms/step - loss: 0.0632 - accuracy: 0.8299\n",
      "Test accuracy with RNN: 0.8299086689949036\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, training embedding layer on the fly\")\n",
    "\n",
    "#modified from: \n",
    "\n",
    "rnnmodel = Sequential()\n",
    "rnnmodel.add(Embedding(MAX_NUM_WORDS, 128))\n",
    "rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel.add(Dense(len(trainvalid_labels[0]), activation='sigmoid'))\n",
    "rnnmodel.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "rnnmodel.summary()\n",
    "\n",
    "print('Training the RNN')\n",
    "rnnmodel.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T03:25:33.571529Z",
     "start_time": "2020-01-21T03:24:04.513325Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tTTJqKFHi_8x",
    "outputId": "d5514ea5-26d4-4c9d-de30-abf6d3adb8a3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training an LSTM model, using pre-trained embedding layer\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 209,241\n",
      "Trainable params: 119,441\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "Training the RNN\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 313s 3s/step - loss: 0.2538 - accuracy: 0.6119 - val_loss: 0.0918 - val_accuracy: 0.7387\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 173s 2s/step - loss: 0.0885 - accuracy: 0.7489 - val_loss: 0.0737 - val_accuracy: 0.8013\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 161s 1s/step - loss: 0.0698 - accuracy: 0.8137 - val_loss: 0.0637 - val_accuracy: 0.8485\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 155s 1s/step - loss: 0.0619 - accuracy: 0.8435 - val_loss: 0.0498 - val_accuracy: 0.8761\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 196s 2s/step - loss: 0.0474 - accuracy: 0.8853 - val_loss: 0.0416 - val_accuracy: 0.8896\n",
      "28/28 [==============================] - 7s 244ms/step - loss: 0.0502 - accuracy: 0.8527\n",
      "Test accuracy with RNN: 0.8527397513389587\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
    "\n",
    "#modified from: \n",
    "\n",
    "rnnmodel2 = Sequential()\n",
    "rnnmodel2.add(embedding_layer)\n",
    "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel2.add(Dense(len(trainvalid_labels[0]), activation='sigmoid'))\n",
    "rnnmodel2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "rnnmodel2.summary()\n",
    "\n",
    "print('Training the RNN')\n",
    "rnnmodel2.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTlSMklki_83"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training an LSTM model, using pre-trained embedding layer\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 209,241\n",
      "Trainable params: 119,441\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "Training the RNN\n",
      "Epoch 1/8\n",
      "109/109 [==============================] - 113s 975ms/step - loss: 0.2415 - accuracy: 0.6326 - val_loss: 0.0833 - val_accuracy: 0.7535\n",
      "Epoch 2/8\n",
      "109/109 [==============================] - 103s 942ms/step - loss: 0.0827 - accuracy: 0.7632 - val_loss: 0.0628 - val_accuracy: 0.8384\n",
      "Epoch 3/8\n",
      "109/109 [==============================] - 121s 1s/step - loss: 0.0682 - accuracy: 0.8211 - val_loss: 0.0489 - val_accuracy: 0.8916\n",
      "Epoch 4/8\n",
      "109/109 [==============================] - 124s 1s/step - loss: 0.0533 - accuracy: 0.8738 - val_loss: 0.0420 - val_accuracy: 0.9010\n",
      "Epoch 5/8\n",
      "109/109 [==============================] - 132s 1s/step - loss: 0.0469 - accuracy: 0.8767 - val_loss: 0.0407 - val_accuracy: 0.8855\n",
      "Epoch 6/8\n",
      "109/109 [==============================] - 132s 1s/step - loss: 0.0411 - accuracy: 0.8949 - val_loss: 0.0322 - val_accuracy: 0.9118\n",
      "Epoch 7/8\n",
      "109/109 [==============================] - 154s 1s/step - loss: 0.0379 - accuracy: 0.9011 - val_loss: 0.0291 - val_accuracy: 0.9212\n",
      "Epoch 8/8\n",
      "109/109 [==============================] - 124s 1s/step - loss: 0.0343 - accuracy: 0.9100 - val_loss: 0.0268 - val_accuracy: 0.9306\n",
      "28/28 [==============================] - 6s 204ms/step - loss: 0.0380 - accuracy: 0.8995\n",
      "Test accuracy with RNN: 0.8995434045791626\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
    "\n",
    "#modified from: \n",
    "\n",
    "rnnmodel2 = Sequential()\n",
    "rnnmodel2.add(embedding_layer)\n",
    "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel2.add(Dense(len(trainvalid_labels[0]), activation='sigmoid'))\n",
    "rnnmodel2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "rnnmodel2.summary()\n",
    "\n",
    "print('Training the RNN')\n",
    "rnnmodel2.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=8,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training an LSTM model, using pre-trained embedding layer\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 209,241\n",
      "Trainable params: 119,441\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "Training the RNN\n",
      "Epoch 1/8\n",
      "55/55 [==============================] - 81s 1s/step - loss: 0.3029 - accuracy: 0.6665 - val_loss: 0.0952 - val_accuracy: 0.7535\n",
      "Epoch 2/8\n",
      "55/55 [==============================] - 66s 1s/step - loss: 0.1019 - accuracy: 0.7208 - val_loss: 0.0861 - val_accuracy: 0.7535\n",
      "Epoch 3/8\n",
      "55/55 [==============================] - 65s 1s/step - loss: 0.0880 - accuracy: 0.7435 - val_loss: 0.0718 - val_accuracy: 0.7953\n",
      "Epoch 4/8\n",
      "55/55 [==============================] - 65s 1s/step - loss: 0.0767 - accuracy: 0.7878 - val_loss: 0.0656 - val_accuracy: 0.8633\n",
      "Epoch 5/8\n",
      "55/55 [==============================] - 69s 1s/step - loss: 0.0695 - accuracy: 0.8284 - val_loss: 0.0521 - val_accuracy: 0.8862\n",
      "Epoch 6/8\n",
      "55/55 [==============================] - 71s 1s/step - loss: 0.0605 - accuracy: 0.8603 - val_loss: 0.0460 - val_accuracy: 0.8943\n",
      "Epoch 7/8\n",
      "55/55 [==============================] - 51s 925ms/step - loss: 0.0518 - accuracy: 0.8782 - val_loss: 0.0427 - val_accuracy: 0.8936\n",
      "Epoch 8/8\n",
      "55/55 [==============================] - 49s 884ms/step - loss: 0.0471 - accuracy: 0.8759 - val_loss: 0.0397 - val_accuracy: 0.8943\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.0508 - accuracy: 0.8516\n",
      "Test accuracy with RNN: 0.8515982031822205\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
    "\n",
    "#modified from: \n",
    "\n",
    "rnnmodel2 = Sequential()\n",
    "rnnmodel2.add(embedding_layer)\n",
    "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel2.add(Dense(len(trainvalid_labels[0]), activation='sigmoid'))\n",
    "rnnmodel2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "rnnmodel2.summary()\n",
    "\n",
    "print('Training the RNN')\n",
    "rnnmodel2.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=8,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training an LSTM model, using pre-trained embedding layer\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 209,241\n",
      "Trainable params: 119,441\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "Training the RNN\n",
      "Epoch 1/8\n",
      "55/55 [==============================] - 75s 1s/step - loss: 0.3115 - accuracy: 0.6264 - val_loss: 0.0951 - val_accuracy: 0.7535\n",
      "Epoch 2/8\n",
      "55/55 [==============================] - 98s 2s/step - loss: 0.0975 - accuracy: 0.7363 - val_loss: 0.0843 - val_accuracy: 0.7535\n",
      "Epoch 3/8\n",
      "55/55 [==============================] - 78s 1s/step - loss: 0.0906 - accuracy: 0.7287 - val_loss: 0.0719 - val_accuracy: 0.8175\n",
      "Epoch 4/8\n",
      "55/55 [==============================] - 75s 1s/step - loss: 0.0742 - accuracy: 0.8094 - val_loss: 0.0670 - val_accuracy: 0.8027\n",
      "Epoch 5/8\n",
      "55/55 [==============================] - 75s 1s/step - loss: 0.0661 - accuracy: 0.8236 - val_loss: 0.0524 - val_accuracy: 0.8842\n",
      "Epoch 6/8\n",
      "55/55 [==============================] - 60s 1s/step - loss: 0.0574 - accuracy: 0.8573 - val_loss: 0.0454 - val_accuracy: 0.8862\n",
      "Epoch 7/8\n",
      "55/55 [==============================] - 50s 912ms/step - loss: 0.0510 - accuracy: 0.8781 - val_loss: 0.0386 - val_accuracy: 0.9064\n",
      "Epoch 8/8\n",
      "55/55 [==============================] - 71s 1s/step - loss: 0.0441 - accuracy: 0.8893 - val_loss: 0.0402 - val_accuracy: 0.8902\n",
      "14/14 [==============================] - 4s 259ms/step - loss: 0.0529 - accuracy: 0.8413\n",
      "Test accuracy with RNN: 0.8413242101669312\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
    "\n",
    "#modified from: \n",
    "\n",
    "rnnmodel2 = Sequential()\n",
    "rnnmodel2.add(embedding_layer)\n",
    "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel2.add(Dense(len(trainvalid_labels[0]), activation='sigmoid'))\n",
    "rnnmodel2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "rnnmodel2.summary()\n",
    "\n",
    "print('Training the RNN')\n",
    "rnnmodel2.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=8,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
    "                            batch_size=64)\n",
    "print('Test accuracy with RNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training an LSTM model, using pre-trained embedding layer\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 209,241\n",
      "Trainable params: 119,441\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "Training the RNN\n",
      "Epoch 1/16\n",
      "109/109 [==============================] - 127s 1s/step - loss: 0.2317 - accuracy: 0.6670 - val_loss: 0.0792 - val_accuracy: 0.7657\n",
      "Epoch 2/16\n",
      "109/109 [==============================] - 125s 1s/step - loss: 0.0864 - accuracy: 0.7606 - val_loss: 0.0585 - val_accuracy: 0.8424\n",
      "Epoch 3/16\n",
      "109/109 [==============================] - 127s 1s/step - loss: 0.0675 - accuracy: 0.8312 - val_loss: 0.0460 - val_accuracy: 0.8909\n",
      "Epoch 4/16\n",
      "109/109 [==============================] - 121s 1s/step - loss: 0.0525 - accuracy: 0.8671 - val_loss: 0.0372 - val_accuracy: 0.9010\n",
      "Epoch 5/16\n",
      "109/109 [==============================] - 83s 759ms/step - loss: 0.0445 - accuracy: 0.8830 - val_loss: 0.0343 - val_accuracy: 0.9158\n",
      "Epoch 6/16\n",
      "109/109 [==============================] - 79s 727ms/step - loss: 0.0370 - accuracy: 0.9071 - val_loss: 0.0275 - val_accuracy: 0.9286\n",
      "Epoch 7/16\n",
      "109/109 [==============================] - 79s 730ms/step - loss: 0.0307 - accuracy: 0.9199 - val_loss: 0.0251 - val_accuracy: 0.9293\n",
      "Epoch 8/16\n",
      "109/109 [==============================] - 79s 723ms/step - loss: 0.0273 - accuracy: 0.9283 - val_loss: 0.0224 - val_accuracy: 0.9414\n",
      "Epoch 9/16\n",
      "109/109 [==============================] - 78s 719ms/step - loss: 0.0255 - accuracy: 0.9329 - val_loss: 0.0203 - val_accuracy: 0.9495\n",
      "Epoch 10/16\n",
      "109/109 [==============================] - 80s 731ms/step - loss: 0.0224 - accuracy: 0.9433 - val_loss: 0.0187 - val_accuracy: 0.9562\n",
      "Epoch 11/16\n",
      "109/109 [==============================] - 79s 721ms/step - loss: 0.0208 - accuracy: 0.9488 - val_loss: 0.0163 - val_accuracy: 0.9596\n",
      "Epoch 12/16\n",
      "109/109 [==============================] - 82s 752ms/step - loss: 0.0188 - accuracy: 0.9551 - val_loss: 0.0142 - val_accuracy: 0.9636\n",
      "Epoch 13/16\n",
      "109/109 [==============================] - 79s 723ms/step - loss: 0.0165 - accuracy: 0.9584 - val_loss: 0.0141 - val_accuracy: 0.9623\n",
      "Epoch 14/16\n",
      "109/109 [==============================] - 82s 752ms/step - loss: 0.0134 - accuracy: 0.9685 - val_loss: 0.0120 - val_accuracy: 0.9697\n",
      "Epoch 15/16\n",
      "109/109 [==============================] - 81s 741ms/step - loss: 0.0137 - accuracy: 0.9702 - val_loss: 0.0117 - val_accuracy: 0.9704\n",
      "Epoch 16/16\n",
      "109/109 [==============================] - 79s 727ms/step - loss: 0.0107 - accuracy: 0.9763 - val_loss: 0.0111 - val_accuracy: 0.9764\n",
      "28/28 [==============================] - 4s 135ms/step - loss: 0.0198 - accuracy: 0.9509\n",
      "Test accuracy with RNN: 0.9509132504463196\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
    "\n",
    "#modified from: \n",
    "\n",
    "rnnmodel2 = Sequential()\n",
    "rnnmodel2.add(embedding_layer)\n",
    "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel2.add(Dense(len(trainvalid_labels[0]), activation='sigmoid'))\n",
    "rnnmodel2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "rnnmodel2.summary()\n",
    "\n",
    "print('Training the RNN')\n",
    "rnnmodel2.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=16,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training an LSTM model, using pre-trained embedding layer\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 209,241\n",
      "Trainable params: 119,441\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "Training the RNN\n",
      "Epoch 1/32\n",
      "109/109 [==============================] - 122s 1s/step - loss: 0.2362 - accuracy: 0.6666 - val_loss: 0.0885 - val_accuracy: 0.7535\n",
      "Epoch 2/32\n",
      "109/109 [==============================] - 104s 949ms/step - loss: 0.0898 - accuracy: 0.7409 - val_loss: 0.0662 - val_accuracy: 0.8276\n",
      "Epoch 3/32\n",
      "109/109 [==============================] - 113s 1s/step - loss: 0.0733 - accuracy: 0.8095 - val_loss: 0.0551 - val_accuracy: 0.8795\n",
      "Epoch 4/32\n",
      "109/109 [==============================] - 118s 1s/step - loss: 0.0573 - accuracy: 0.8629 - val_loss: 0.0408 - val_accuracy: 0.8997\n",
      "Epoch 5/32\n",
      "109/109 [==============================] - 121s 1s/step - loss: 0.0441 - accuracy: 0.8889 - val_loss: 0.0360 - val_accuracy: 0.9010\n",
      "Epoch 6/32\n",
      "109/109 [==============================] - 128s 1s/step - loss: 0.0384 - accuracy: 0.9011 - val_loss: 0.0312 - val_accuracy: 0.9226\n",
      "Epoch 7/32\n",
      "109/109 [==============================] - 122s 1s/step - loss: 0.0331 - accuracy: 0.9149 - val_loss: 0.0287 - val_accuracy: 0.9266\n",
      "Epoch 8/32\n",
      "109/109 [==============================] - 125s 1s/step - loss: 0.0320 - accuracy: 0.9201 - val_loss: 0.0261 - val_accuracy: 0.9407\n",
      "Epoch 9/32\n",
      "109/109 [==============================] - 129s 1s/step - loss: 0.0286 - accuracy: 0.9287 - val_loss: 0.0224 - val_accuracy: 0.9461\n",
      "Epoch 10/32\n",
      "109/109 [==============================] - 129s 1s/step - loss: 0.0256 - accuracy: 0.9316 - val_loss: 0.0209 - val_accuracy: 0.9522\n",
      "Epoch 11/32\n",
      "109/109 [==============================] - 128s 1s/step - loss: 0.0233 - accuracy: 0.9377 - val_loss: 0.0188 - val_accuracy: 0.9576\n",
      "Epoch 12/32\n",
      "109/109 [==============================] - 125s 1s/step - loss: 0.0213 - accuracy: 0.9481 - val_loss: 0.0177 - val_accuracy: 0.9556\n",
      "Epoch 13/32\n",
      "109/109 [==============================] - 125s 1s/step - loss: 0.0192 - accuracy: 0.9524 - val_loss: 0.0157 - val_accuracy: 0.9596\n",
      "Epoch 14/32\n",
      "109/109 [==============================] - 131s 1s/step - loss: 0.0181 - accuracy: 0.9538 - val_loss: 0.0158 - val_accuracy: 0.9643\n",
      "Epoch 15/32\n",
      "109/109 [==============================] - 162s 1s/step - loss: 0.0151 - accuracy: 0.9630 - val_loss: 0.0149 - val_accuracy: 0.9630\n",
      "Epoch 16/32\n",
      "109/109 [==============================] - 125s 1s/step - loss: 0.0140 - accuracy: 0.9701 - val_loss: 0.0130 - val_accuracy: 0.9690\n",
      "Epoch 17/32\n",
      "109/109 [==============================] - 126s 1s/step - loss: 0.0144 - accuracy: 0.9627 - val_loss: 0.0145 - val_accuracy: 0.9677\n",
      "Epoch 18/32\n",
      "109/109 [==============================] - 130s 1s/step - loss: 0.0134 - accuracy: 0.9676 - val_loss: 0.0121 - val_accuracy: 0.9724\n",
      "Epoch 19/32\n",
      "109/109 [==============================] - 125s 1s/step - loss: 0.0103 - accuracy: 0.9784 - val_loss: 0.0126 - val_accuracy: 0.9697\n",
      "Epoch 20/32\n",
      "109/109 [==============================] - 129s 1s/step - loss: 0.0118 - accuracy: 0.9757 - val_loss: 0.0112 - val_accuracy: 0.9731\n",
      "Epoch 21/32\n",
      "109/109 [==============================] - 126s 1s/step - loss: 0.0110 - accuracy: 0.9737 - val_loss: 0.0110 - val_accuracy: 0.9751\n",
      "Epoch 22/32\n",
      "109/109 [==============================] - 129s 1s/step - loss: 0.0089 - accuracy: 0.9805 - val_loss: 0.0106 - val_accuracy: 0.9764\n",
      "Epoch 23/32\n",
      "109/109 [==============================] - 128s 1s/step - loss: 0.0091 - accuracy: 0.9851 - val_loss: 0.0106 - val_accuracy: 0.9778\n",
      "Epoch 24/32\n",
      "109/109 [==============================] - 128s 1s/step - loss: 0.0098 - accuracy: 0.9789 - val_loss: 0.0095 - val_accuracy: 0.9785\n",
      "Epoch 25/32\n",
      "109/109 [==============================] - 134s 1s/step - loss: 0.0081 - accuracy: 0.9815 - val_loss: 0.0099 - val_accuracy: 0.9798\n",
      "Epoch 26/32\n",
      "109/109 [==============================] - 128s 1s/step - loss: 0.0071 - accuracy: 0.9845 - val_loss: 0.0098 - val_accuracy: 0.9811\n",
      "Epoch 27/32\n",
      "109/109 [==============================] - 130s 1s/step - loss: 0.0078 - accuracy: 0.9823 - val_loss: 0.0088 - val_accuracy: 0.9811\n",
      "Epoch 28/32\n",
      "109/109 [==============================] - 127s 1s/step - loss: 0.0074 - accuracy: 0.9846 - val_loss: 0.0085 - val_accuracy: 0.9798\n",
      "Epoch 29/32\n",
      "109/109 [==============================] - 129s 1s/step - loss: 0.0062 - accuracy: 0.9890 - val_loss: 0.0090 - val_accuracy: 0.9785\n",
      "Epoch 30/32\n",
      "109/109 [==============================] - 129s 1s/step - loss: 0.0059 - accuracy: 0.9894 - val_loss: 0.0093 - val_accuracy: 0.9805\n",
      "Epoch 31/32\n",
      "109/109 [==============================] - 131s 1s/step - loss: 0.0065 - accuracy: 0.9865 - val_loss: 0.0085 - val_accuracy: 0.9811\n",
      "Epoch 32/32\n",
      "109/109 [==============================] - 136s 1s/step - loss: 0.0059 - accuracy: 0.9887 - val_loss: 0.0086 - val_accuracy: 0.9805\n",
      "28/28 [==============================] - 5s 189ms/step - loss: 0.0136 - accuracy: 0.9737\n",
      "Test accuracy with RNN: 0.97374427318573\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
    "\n",
    "#modified from: \n",
    "\n",
    "rnnmodel2 = Sequential()\n",
    "rnnmodel2.add(embedding_layer)\n",
    "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel2.add(Dense(len(trainvalid_labels[0]), activation='sigmoid'))\n",
    "rnnmodel2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "rnnmodel2.summary()\n",
    "\n",
    "print('Training the RNN')\n",
    "rnnmodel2.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=32,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defining and training an LSTM model, using pre-trained embedding layer\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 100)          89800     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 209,241\n",
      "Trainable params: 119,441\n",
      "Non-trainable params: 89,800\n",
      "_________________________________________________________________\n",
      "Training the RNN\n",
      "Epoch 1/64\n",
      "109/109 [==============================] - 115s 989ms/step - loss: 0.2417 - accuracy: 0.6527 - val_loss: 0.0905 - val_accuracy: 0.7535\n",
      "Epoch 2/64\n",
      "109/109 [==============================] - 105s 963ms/step - loss: 0.0917 - accuracy: 0.7383 - val_loss: 0.0730 - val_accuracy: 0.8229\n",
      "Epoch 3/64\n",
      "109/109 [==============================] - 110s 1s/step - loss: 0.0752 - accuracy: 0.7911 - val_loss: 0.0583 - val_accuracy: 0.8343\n",
      "Epoch 4/64\n",
      "109/109 [==============================] - 110s 1s/step - loss: 0.0618 - accuracy: 0.8381 - val_loss: 0.0485 - val_accuracy: 0.8855\n",
      "Epoch 5/64\n",
      "109/109 [==============================] - 115s 1s/step - loss: 0.0556 - accuracy: 0.8577 - val_loss: 0.0414 - val_accuracy: 0.8976\n",
      "Epoch 6/64\n",
      "109/109 [==============================] - 121s 1s/step - loss: 0.0483 - accuracy: 0.8762 - val_loss: 0.0386 - val_accuracy: 0.9030\n",
      "Epoch 7/64\n",
      "109/109 [==============================] - 115s 1s/step - loss: 0.0434 - accuracy: 0.8859 - val_loss: 0.0329 - val_accuracy: 0.9091\n",
      "Epoch 8/64\n",
      "109/109 [==============================] - 118s 1s/step - loss: 0.0382 - accuracy: 0.9007 - val_loss: 0.0319 - val_accuracy: 0.9138\n",
      "Epoch 9/64\n",
      "109/109 [==============================] - 121s 1s/step - loss: 0.0349 - accuracy: 0.9071 - val_loss: 0.0279 - val_accuracy: 0.9273\n",
      "Epoch 10/64\n",
      "109/109 [==============================] - 119s 1s/step - loss: 0.0334 - accuracy: 0.9142 - val_loss: 0.0269 - val_accuracy: 0.9306\n",
      "Epoch 11/64\n",
      "109/109 [==============================] - 125s 1s/step - loss: 0.0303 - accuracy: 0.9201 - val_loss: 0.0238 - val_accuracy: 0.9394\n",
      "Epoch 12/64\n",
      "109/109 [==============================] - 134s 1s/step - loss: 0.0272 - accuracy: 0.9288 - val_loss: 0.0217 - val_accuracy: 0.9461\n",
      "Epoch 13/64\n",
      "109/109 [==============================] - 169s 2s/step - loss: 0.0255 - accuracy: 0.9317 - val_loss: 0.0201 - val_accuracy: 0.9529\n",
      "Epoch 14/64\n",
      "109/109 [==============================] - 120s 1s/step - loss: 0.0211 - accuracy: 0.9450 - val_loss: 0.0201 - val_accuracy: 0.9562\n",
      "Epoch 15/64\n",
      "109/109 [==============================] - 127s 1s/step - loss: 0.0212 - accuracy: 0.9462 - val_loss: 0.0177 - val_accuracy: 0.9589\n",
      "Epoch 16/64\n",
      "109/109 [==============================] - 140s 1s/step - loss: 0.0209 - accuracy: 0.9415 - val_loss: 0.0170 - val_accuracy: 0.9576\n",
      "Epoch 17/64\n",
      "109/109 [==============================] - 142s 1s/step - loss: 0.0182 - accuracy: 0.9542 - val_loss: 0.0165 - val_accuracy: 0.9589\n",
      "Epoch 18/64\n",
      "109/109 [==============================] - 125s 1s/step - loss: 0.0164 - accuracy: 0.9545 - val_loss: 0.0189 - val_accuracy: 0.9549\n",
      "Epoch 19/64\n",
      "109/109 [==============================] - 122s 1s/step - loss: 0.0158 - accuracy: 0.9638 - val_loss: 0.0145 - val_accuracy: 0.9643\n",
      "Epoch 20/64\n",
      "109/109 [==============================] - 124s 1s/step - loss: 0.0126 - accuracy: 0.9718 - val_loss: 0.0151 - val_accuracy: 0.9636\n",
      "Epoch 21/64\n",
      "109/109 [==============================] - 122s 1s/step - loss: 0.0142 - accuracy: 0.9660 - val_loss: 0.0140 - val_accuracy: 0.9636\n",
      "Epoch 22/64\n",
      "109/109 [==============================] - 121s 1s/step - loss: 0.0120 - accuracy: 0.9727 - val_loss: 0.0133 - val_accuracy: 0.9663\n",
      "Epoch 23/64\n",
      "109/109 [==============================] - 122s 1s/step - loss: 0.0106 - accuracy: 0.9768 - val_loss: 0.0128 - val_accuracy: 0.9677\n",
      "Epoch 24/64\n",
      "109/109 [==============================] - 121s 1s/step - loss: 0.0104 - accuracy: 0.9769 - val_loss: 0.0124 - val_accuracy: 0.9697\n",
      "Epoch 25/64\n",
      "109/109 [==============================] - 130s 1s/step - loss: 0.0097 - accuracy: 0.9791 - val_loss: 0.0120 - val_accuracy: 0.9724\n",
      "Epoch 26/64\n",
      "109/109 [==============================] - 124s 1s/step - loss: 0.0109 - accuracy: 0.9747 - val_loss: 0.0117 - val_accuracy: 0.9704\n",
      "Epoch 27/64\n",
      "109/109 [==============================] - 122s 1s/step - loss: 0.0090 - accuracy: 0.9805 - val_loss: 0.0115 - val_accuracy: 0.9697\n",
      "Epoch 28/64\n",
      "109/109 [==============================] - 122s 1s/step - loss: 0.0082 - accuracy: 0.9820 - val_loss: 0.0103 - val_accuracy: 0.9744\n",
      "Epoch 29/64\n",
      "109/109 [==============================] - 93s 853ms/step - loss: 0.0085 - accuracy: 0.9806 - val_loss: 0.0098 - val_accuracy: 0.9764\n",
      "Epoch 30/64\n",
      "109/109 [==============================] - 79s 726ms/step - loss: 0.0074 - accuracy: 0.9846 - val_loss: 0.0095 - val_accuracy: 0.9778\n",
      "Epoch 31/64\n",
      "109/109 [==============================] - 83s 764ms/step - loss: 0.0075 - accuracy: 0.9863 - val_loss: 0.0097 - val_accuracy: 0.9744\n",
      "Epoch 32/64\n",
      "109/109 [==============================] - 91s 836ms/step - loss: 0.0063 - accuracy: 0.9872 - val_loss: 0.0095 - val_accuracy: 0.9771\n",
      "Epoch 33/64\n",
      "109/109 [==============================] - 90s 826ms/step - loss: 0.0078 - accuracy: 0.9798 - val_loss: 0.0101 - val_accuracy: 0.9751\n",
      "Epoch 34/64\n",
      "109/109 [==============================] - 91s 839ms/step - loss: 0.0068 - accuracy: 0.9880 - val_loss: 0.0092 - val_accuracy: 0.9778\n",
      "Epoch 35/64\n",
      "109/109 [==============================] - 82s 753ms/step - loss: 0.0066 - accuracy: 0.9855 - val_loss: 0.0098 - val_accuracy: 0.9764\n",
      "Epoch 36/64\n",
      "109/109 [==============================] - 84s 770ms/step - loss: 0.0058 - accuracy: 0.9888 - val_loss: 0.0095 - val_accuracy: 0.9737\n",
      "Epoch 37/64\n",
      "109/109 [==============================] - 83s 764ms/step - loss: 0.0063 - accuracy: 0.9864 - val_loss: 0.0088 - val_accuracy: 0.9751\n",
      "Epoch 38/64\n",
      "109/109 [==============================] - 87s 801ms/step - loss: 0.0058 - accuracy: 0.9840 - val_loss: 0.0089 - val_accuracy: 0.9764\n",
      "Epoch 39/64\n",
      "109/109 [==============================] - 85s 778ms/step - loss: 0.0043 - accuracy: 0.9923 - val_loss: 0.0082 - val_accuracy: 0.9798\n",
      "Epoch 40/64\n",
      "109/109 [==============================] - 83s 759ms/step - loss: 0.0038 - accuracy: 0.9937 - val_loss: 0.0084 - val_accuracy: 0.9785\n",
      "Epoch 41/64\n",
      "109/109 [==============================] - 84s 770ms/step - loss: 0.0042 - accuracy: 0.9922 - val_loss: 0.0088 - val_accuracy: 0.9764\n",
      "Epoch 42/64\n",
      "109/109 [==============================] - 83s 758ms/step - loss: 0.0035 - accuracy: 0.9956 - val_loss: 0.0081 - val_accuracy: 0.9785\n",
      "Epoch 43/64\n",
      "109/109 [==============================] - 87s 800ms/step - loss: 0.0039 - accuracy: 0.9921 - val_loss: 0.0081 - val_accuracy: 0.9778\n",
      "Epoch 44/64\n",
      "109/109 [==============================] - 121s 1s/step - loss: 0.0034 - accuracy: 0.9933 - val_loss: 0.0090 - val_accuracy: 0.9758\n",
      "Epoch 45/64\n",
      "109/109 [==============================] - 83s 762ms/step - loss: 0.0030 - accuracy: 0.9971 - val_loss: 0.0085 - val_accuracy: 0.9778\n",
      "Epoch 46/64\n",
      "109/109 [==============================] - 88s 811ms/step - loss: 0.0038 - accuracy: 0.9936 - val_loss: 0.0083 - val_accuracy: 0.9805\n",
      "Epoch 47/64\n",
      "109/109 [==============================] - 84s 769ms/step - loss: 0.0031 - accuracy: 0.9915 - val_loss: 0.0082 - val_accuracy: 0.9785\n",
      "Epoch 48/64\n",
      "109/109 [==============================] - 84s 772ms/step - loss: 0.0022 - accuracy: 0.9971 - val_loss: 0.0087 - val_accuracy: 0.9798\n",
      "Epoch 49/64\n",
      "109/109 [==============================] - 84s 769ms/step - loss: 0.0026 - accuracy: 0.9959 - val_loss: 0.0082 - val_accuracy: 0.9798\n",
      "Epoch 50/64\n",
      "109/109 [==============================] - 82s 755ms/step - loss: 0.0024 - accuracy: 0.9962 - val_loss: 0.0083 - val_accuracy: 0.9798\n",
      "Epoch 51/64\n",
      "109/109 [==============================] - 116s 1s/step - loss: 0.0026 - accuracy: 0.9928 - val_loss: 0.0078 - val_accuracy: 0.9785\n",
      "Epoch 52/64\n",
      "109/109 [==============================] - 83s 763ms/step - loss: 0.0026 - accuracy: 0.9950 - val_loss: 0.0088 - val_accuracy: 0.9805\n",
      "Epoch 53/64\n",
      "109/109 [==============================] - 84s 770ms/step - loss: 0.0024 - accuracy: 0.9964 - val_loss: 0.0080 - val_accuracy: 0.9805\n",
      "Epoch 54/64\n",
      "109/109 [==============================] - 85s 781ms/step - loss: 0.0018 - accuracy: 0.9971 - val_loss: 0.0080 - val_accuracy: 0.9791\n",
      "Epoch 55/64\n",
      "109/109 [==============================] - 84s 771ms/step - loss: 0.0026 - accuracy: 0.9958 - val_loss: 0.0078 - val_accuracy: 0.9791\n",
      "Epoch 56/64\n",
      "109/109 [==============================] - 84s 772ms/step - loss: 0.0021 - accuracy: 0.9966 - val_loss: 0.0077 - val_accuracy: 0.9791\n",
      "Epoch 57/64\n",
      "109/109 [==============================] - 84s 770ms/step - loss: 0.0027 - accuracy: 0.9957 - val_loss: 0.0075 - val_accuracy: 0.9811\n",
      "Epoch 58/64\n",
      "109/109 [==============================] - 86s 787ms/step - loss: 0.0015 - accuracy: 0.9984 - val_loss: 0.0075 - val_accuracy: 0.9811\n",
      "Epoch 59/64\n",
      "109/109 [==============================] - 83s 758ms/step - loss: 0.0015 - accuracy: 0.9974 - val_loss: 0.0083 - val_accuracy: 0.9798\n",
      "Epoch 60/64\n",
      "109/109 [==============================] - 86s 788ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 0.0078 - val_accuracy: 0.9818\n",
      "Epoch 61/64\n",
      "109/109 [==============================] - 84s 771ms/step - loss: 0.0021 - accuracy: 0.9976 - val_loss: 0.0087 - val_accuracy: 0.9818\n",
      "Epoch 62/64\n",
      "109/109 [==============================] - 83s 765ms/step - loss: 0.0016 - accuracy: 0.9979 - val_loss: 0.0082 - val_accuracy: 0.9818\n",
      "Epoch 63/64\n",
      "109/109 [==============================] - 83s 758ms/step - loss: 0.0016 - accuracy: 0.9979 - val_loss: 0.0082 - val_accuracy: 0.9825\n",
      "Epoch 64/64\n",
      "109/109 [==============================] - 84s 773ms/step - loss: 0.0019 - accuracy: 0.9968 - val_loss: 0.0077 - val_accuracy: 0.9838\n",
      "28/28 [==============================] - 4s 134ms/step - loss: 0.0108 - accuracy: 0.9817\n",
      "Test accuracy with RNN: 0.9817351698875427\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining and training an LSTM model, using pre-trained embedding layer\")\n",
    "\n",
    "#modified from: \n",
    "\n",
    "rnnmodel2 = Sequential()\n",
    "rnnmodel2.add(embedding_layer)\n",
    "rnnmodel2.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnnmodel2.add(Dense(len(trainvalid_labels[0]), activation='sigmoid'))\n",
    "rnnmodel2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "rnnmodel2.summary()\n",
    "\n",
    "print('Training the RNN')\n",
    "rnnmodel2.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=64,\n",
    "          validation_data=(x_val, y_val))\n",
    "score, acc = rnnmodel2.evaluate(test_data, test_labels,\n",
    "                            batch_size=32)\n",
    "print('Test accuracy with RNN:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: onnxmltools in /usr/local/lib/python3.8/dist-packages (1.7.0)\n",
      "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.8/dist-packages (1.7.0)\n",
      "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.8/dist-packages (1.8.5)\n",
      "Requirement already satisfied: keras2onnx in /usr/local/lib/python3.8/dist-packages (1.7.0)\n",
      "Requirement already satisfied: skl2onnx in /usr/local/lib/python3.8/dist-packages (from onnxmltools) (1.8.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from onnxmltools) (1.19.5)\n",
      "Requirement already satisfied: onnxconverter-common<1.8.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from onnxmltools) (1.7.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxmltools) (3.15.7)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.8/dist-packages (from onnxmltools) (1.9.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (2.25.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx->onnxmltools) (3.7.4.3)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.8/dist-packages (from keras2onnx) (0.4.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->keras2onnx) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->tf2onnx) (3.0.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from skl2onnx->onnxmltools) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.8/dist-packages (from skl2onnx->onnxmltools) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19->skl2onnx->onnxmltools) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19->skl2onnx->onnxmltools) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxmltools onnxruntime tf2onnx keras2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(onnxmltools.convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_KERAS']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['TF_KERAS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/hlaz001/practicalnlp/Ch6\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: model_path2/assets\n"
     ]
    }
   ],
   "source": [
    "cnnmodel.save('model_path2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "cnnmodel_restored = keras.models.load_model('model_path2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'sequential_1'"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "cnnmodel_restored.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "test_labels[0].reshape(1,17).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0114 - acc: 1.0000\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score2, acc2 = cnnmodel.evaluate(test_data[350].reshape(1,300), test_labels[350].reshape(1,17))\n",
    "print(acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "len(test_data[0].reshape(1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'graph'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-c46413ffe9fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnnmodel_restored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "cnnmodel_restored.outputs[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cnnmodel_restored.predict(test_data[0].reshape(1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.00085111876251176,\n",
       "  0.001417235704138875,\n",
       "  0.006768747232854366,\n",
       "  0.0035902531817555428,\n",
       "  0.00019047834211960435,\n",
       "  4.9524136557010934e-05,\n",
       "  1.985645758395549e-05,\n",
       "  8.106949098873883e-05,\n",
       "  0.0002301860076840967,\n",
       "  0.9799414873123169,\n",
       "  0.00015161065675783902,\n",
       "  0.0006940678576938808,\n",
       "  8.792074368102476e-05,\n",
       "  0.00517652602866292,\n",
       "  4.419558172230609e-05,\n",
       "  0.0006731032044626772,\n",
       "  3.2594431104371324e-05]]"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.000405784317990765,\n",
       "  0.0019435544963926077,\n",
       "  0.04649471864104271,\n",
       "  0.0029041613452136517,\n",
       "  3.46479173458647e-05,\n",
       "  0.00010881847993005067,\n",
       "  0.0002588485076557845,\n",
       "  0.00014623059541918337,\n",
       "  0.0001420097250957042,\n",
       "  0.9415048956871033,\n",
       "  0.0005090154008939862,\n",
       "  0.0017443564720451832,\n",
       "  0.00017915127682499588,\n",
       "  0.0027891064528375864,\n",
       "  4.667467510444112e-05,\n",
       "  0.000731141131836921,\n",
       "  5.677477747667581e-05]]"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "prediction2 = cnnmodel.predict(test_data[0].reshape(1,300))\n",
    "prediction2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'graph'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-9b583f0c9af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#onnxmltools.utils.save_model(onnx_model, 'keras_cnn.onnx')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#onnx_model = keras2onnx.convert_keras(cnnmodel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mkeras2onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnnmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnnmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras2onnx/main.py\u001b[0m in \u001b[0;36mconvert_keras\u001b[0;34m(model, name, doc_string, target_opset, channel_first_inputs, debug_mode, custom_op_conversions)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_tf2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_tf_keras\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtf_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_layer_output_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mtf_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras2onnx/_parser_tf.py\u001b[0m in \u001b[0;36mbuild_layer_output_from_model\u001b[0;34m(model, output_dict, input_names, output_names)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mextract_outputs_from_subclassing_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0moutput_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0moutput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_outputs_from_inbound_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "import onnxmltools\n",
    "import tf2onnx\n",
    "import keras2onnx\n",
    "\n",
    "#onnx_model = onnxmltools.convert_tensorflow(cnnmodel)\n",
    "#onnxmltools.utils.save_model(onnx_model, 'keras_cnn.onnx')\n",
    "#onnx_model = keras2onnx.convert_keras(cnnmodel)\n",
    "#keras2onnx.convert_keras(cnnmodel, cnnmodel.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on method save in module tensorflow.python.keras.engine.training:\n\nsave(filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True) method of tensorflow.python.keras.engine.sequential.Sequential instance\n    Saves the model to Tensorflow SavedModel or a single HDF5 file.\n    \n    Please see `tf.keras.models.save_model` or the\n    [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n    for details.\n    \n    Arguments:\n        filepath: String, PathLike, path to SavedModel or H5 file to save the\n            model.\n        overwrite: Whether to silently overwrite any existing file at the\n            target location, or provide the user with a manual prompt.\n        include_optimizer: If True, save optimizer's state together.\n        save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n            model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n            and 'h5' in TF 1.X.\n        signatures: Signatures to save with the SavedModel. Applicable to the\n            'tf' format only. Please see the `signatures` argument in\n            `tf.saved_model.save` for details.\n        options: (only applies to SavedModel format)\n            `tf.saved_model.SaveOptions` object that specifies options for\n            saving to SavedModel.\n        save_traces: (only applies to SavedModel format) When enabled, the\n            SavedModel will store the function traces for each layer. This\n            can be disabled, so that only the configs of each layer are stored.\n            Defaults to `True`. Disabling this will decrease serialization time\n            and reduce file size, but it requires that all custom layers/models\n            implement a `get_config()` method.\n    \n    Example:\n    \n    ```python\n    from keras.models import load_model\n    \n    model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n    del model  # deletes the existing model\n    \n    # returns a compiled model\n    # identical to the previous one\n    model = load_model('my_model.h5')\n    ```\n\n"
     ]
    }
   ],
   "source": [
    "help(cnnmodel.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel.save(\"cnnmodel_Ch6_01_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cnnmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel_reload=load_model(\"cnnmodel_Ch6_01_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cnnmodel_reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN_RNN_ATIS_intents.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}